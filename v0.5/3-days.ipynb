{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim import corpora, models\n",
    "from gensim.models import Phrases\n",
    "from sklearn import decomposition\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "import pyLDAvis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# initialize tokenizer and stopwords\n",
    "en_stop = ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as',\n",
    "           'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot',\n",
    "           'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each',\n",
    "           'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\",\n",
    "           \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\",\n",
    "           \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more',\n",
    "           'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought',\n",
    "           'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should',\n",
    "           \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then',\n",
    "           'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to',\n",
    "           'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\",\n",
    "           'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\",\n",
    "           'with', \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself',\n",
    "           'yourselves', 'apos', '&apos;m', '&apos;re', '&apos;s', 's', 'I', 'will', 'go', 'get', '(', ')', '?', ':', ';', ',', '.', '!',\n",
    "           '/', '\"', \"'\", \"...\",\"``\", \"&apos\", \"&apos;s\", \"&apos;&apos;\", \"-lsb-\", \"-rsb-\", \"-lcb-\", \"-rcb-\", \"-lrb-\", \"-rrb-\",\n",
    "           \"O&apos;MALLEY\", \"--\", \" \"]\n",
    "en_stop_stories = ['(', ')', '?', ':', ';', ',', '.', '!', '/', '\"', \"'\", \"...\",\"``\", \"-lsb-\", \"-rsb-\", \"-lcb-\", \"-rcb-\", \"-lrb-\", \"-rrb-\", \"--\", \" \"]\n",
    "\n",
    "stop_chars = ['<', '>']\n",
    "\n",
    "# get all lemmas between a <story>-</story>-pair:\n",
    "stories = []\n",
    "lemma_stories = []\n",
    "\n",
    "with open('3-4-5_story_test.txt') as infile:\n",
    "    for line in infile:\n",
    "        l = line.rstrip()\n",
    "        if l == \"<story>\":\n",
    "            story = []\n",
    "        elif l == \"</story>\":\n",
    "            stories.append(story)\n",
    "        else:\n",
    "            if l not in en_stop_stories:\n",
    "                story.append(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('3-4-5_lemma_test.txt') as infile:\n",
    "    for line in infile:\n",
    "        l = line.rstrip()\n",
    "        if l == \"<story>\":\n",
    "            story = []\n",
    "        elif l == \"</story>\":\n",
    "            lemma_stories.append(story)\n",
    "        elif not any(stop_char in l for stop_char in stop_chars):\n",
    "            if l not in en_stop:\n",
    "                story.append(l)\n",
    "\n",
    "# create dictionary and wordcounts corpus:\n",
    "dictionary = corpora.Dictionary(lemma_stories)\n",
    "#print(dictionary.token2id)\n",
    "#dictionary.save(\"wordcounts.dict\")\n",
    "\n",
    "print(len(dictionary))\n",
    "\n",
    "\n",
    "# Bag-of-words representation of the stories.\n",
    "corpus = [dictionary.doc2bow(story) for story in lemma_stories]\n",
    "#print(corpus)\n",
    "#corpora.MmCorpus.serialize(\"corpus.mm\", corpus)\n",
    "print(len(corpus))\n",
    "print(len(stories))\n",
    "print(len(lemma_stories))\n",
    "\n",
    "# create tf.idf model:\n",
    "tfidf_model = models.TfidfModel(corpus)\n",
    "#tfidf_model.save(\"tfidf_model\")\n",
    "tfidf_corpus = tfidf_model[corpus]\n",
    "#print(tfidf_corpus)\n",
    "#print(tfidf_corpus.chunksize)\n",
    "# corpora.MmCorpus.serialize(\"tfidf_corpus.mm\", tfidf_corpus)\n",
    "#\n",
    "# # create topic models:\n",
    "# LDA\n",
    "num_topics = 100\n",
    "\n",
    "lda_model = models.ldamodel.LdaModel(corpus=tfidf_corpus, id2word=dictionary, num_topics=num_topics, update_every=0, chunksize=5000, passes=20)\n",
    "#lda_model.save(\"lda_model\")\n",
    "lda_corpus = lda_model[tfidf_corpus]\n",
    "#corpora.MmCorpus.serialize(\"lda_corpus.mm\", lda_corpus)\n",
    "\n",
    "print(\"\\nTopics by Latent Dirichlet Allocation model\")\n",
    "topics_found_lda = lda_model.print_topics(num_topics=5, num_words=10)\n",
    "all_topics = lda_model.print_topics(num_topics=100, num_words=10)\n",
    "\n",
    "# print(topics_found_lda)\n",
    "\n",
    "\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for t in topics_found_lda:\n",
    "    print(\"Topic #{} {}\".format(counter, t))\n",
    "    words = re.findall('\"([^\"]+)\"', t[1])\n",
    "    words = ' '.join(words)\n",
    "    print(words)\n",
    "    counter += 1\n",
    "\n",
    "topics = []\n",
    "for t in all_topics:\n",
    "    words = re.findall('\"([^\"]+)\"', t[1])\n",
    "    words = ' '.join(words)\n",
    "    topics.append(words)\n",
    "\n",
    "print(topics)\n",
    "topics.extend((\"Stories with actual words\", \"Number of subelements in stories with actual words\", \"Stories with lemmas\",\n",
    "               \"Number of subelements in stories with lemmas\"))\n",
    "len(topics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(16, 0.25743585570059729), (65, 0.56170294158152745)]\n"
     ]
    }
   ],
   "source": [
    "lda_df = pd.DataFrame(columns=range(100))\n",
    "\n",
    "for i in range(len(lemma_stories)):\n",
    "    doc = lda_corpus[i]\n",
    "    for top, prob in doc:\n",
    "        lda_df.set_value(i, top, prob)\n",
    "print(doc)\n",
    "\n",
    "with open(\"3-4-5_Output.txt\", \"w\") as text_file:\n",
    "    text_file.write(\"Doc: %s\" % (doc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lda_df.to_csv(\"1-2-3_df.csv\")\n",
    "#lda_df\n",
    "# with open(\"1-2-3_lemma.txt\", \"w\") as lemma_file:\n",
    "#     for item in lemma_stories:\n",
    "#         lemma_file.write(\"%s\\n\" % item)\n",
    "# with open(\"1-2-3_story.txt\", \"w\") as story_file:\n",
    "#     for item in stories:\n",
    "#         story_file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731\n",
      "3734\n",
      "3731\n"
     ]
    }
   ],
   "source": [
    "lemma_stories2 = [x for x in lemma_stories if x]\n",
    "stories2 = [x for x in stories if x]\n",
    "\n",
    "with open(\"3-4-5_new_lemma.txt\", \"w\") as lemma_file:\n",
    "    for item in lemma_stories2:\n",
    "        lemma_file.write(\"%s\\n\" % item)\n",
    "with open(\"3-4-5_new_story.txt\", \"w\") as story_file:\n",
    "    for item in stories2:\n",
    "        story_file.write(\"%s\\n\" % item)\n",
    "print(len(lemma_stories2))\n",
    "print(len(stories2))\n",
    "print(len(lda_df))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Extreme', 'weather', 'Cleanup', 'efforts', 'way', 'Illinois', 'Missouri', 'floodwater', 'pumped', 'overflowing', 'roadways', 'In', 'Alexander', 'County', 'Illinois', '100', 'homes', 'flooded', 'levees', 'strain', 'keep', 'water', 'spilling', 'Then', 'St.', 'Louis', 'flooding', 'concerns', 'real', 'swollen', 'Mississippi', 'River', 'least', '31', 'people', 'died', 'state', 'due', 'historic', 'flooding', 'Those', 'headlines', 'See', 'You', 'shortly', 'Monday', 'morning', 'Water', 'water', 'everywhere', 'Thank', 'much']\n"
     ]
    }
   ],
   "source": [
    "# print(\"stories:\")\n",
    "# for x in stories2:\n",
    "#     if set(x).issubset(en_stop)== True:\n",
    "#         print(x)\n",
    "#     elif len(x) < 3:\n",
    "#         print(x)\n",
    "\n",
    "#del stories2[1585]\n",
    "print(stories2[1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2961"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lda_df[-1] = stories2\n",
    "lda_df[-2] = lda_df[-1].apply(lambda x: len(x))\n",
    "lda_df[-3] = lemma_stories2 # Not a good indicator\n",
    "lda_df[-4] = lda_df[-3].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "lda_df.loc[-1] = topics  # adding a row\n",
    "\n",
    "lda_df.index = lda_df.index + 1  # shifting index\n",
    "\n",
    "lda_df = lda_df.sort_index() # moving up\n",
    "\n",
    "lda_df.reset_index(drop=True, inplace=True)\n",
    "lda_df.to_csv('3-4-5_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'story' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-45b505f69c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mstories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0men_stop_stories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mstory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'story' is not defined"
     ]
    }
   ],
   "source": [
    "en_stop_stories = ['(', ')', '?', ':', ';', ',', '.', '!', '/', '\"', \"'\", \"...\",\"``\", \"-lsb-\", \"-rsb-\", \"-lcb-\", \"-rcb-\", \"-lrb-\", \"-rrb-\", \"--\", \" \"]\n",
    "\n",
    "stories = []\n",
    "\n",
    "with open('3-4-5_story_test.txt') as infile:\n",
    "    for line in infile:\n",
    "        l = line.rstrip()\n",
    "        if l == \"<story>\":\n",
    "            story = []\n",
    "        elif l == \"</story>\":\n",
    "            stories.append(story)\n",
    "        elif l not in en_stop_stories:\n",
    "            story.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
