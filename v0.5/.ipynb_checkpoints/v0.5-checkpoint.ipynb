{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim import corpora, models\n",
    "from gensim.models import Phrases\n",
    "from sklearn import decomposition\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "import pyLDAvis\n",
    "import pandas as pd\n",
    "\n",
    "# initialize tokenizer and stopwords\n",
    "en_stop = ['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as',\n",
    "           'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot',\n",
    "           'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each',\n",
    "           'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\",\n",
    "           \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\",\n",
    "           \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more',\n",
    "           'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought',\n",
    "           'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should',\n",
    "           \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then',\n",
    "           'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to',\n",
    "           'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\",\n",
    "           'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\",\n",
    "           'with', \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself',\n",
    "           'yourselves', 'apos', '&apos;m', '&apos;re', '&apos;s', 's', 'I', 'will', 'go', 'get', '(', ')', '?', ':', ';', ',', '.', '!',\n",
    "           '/', '\"', \"'\", \"...\",\"``\", \"&apos\", \"&apos;s\", \"&apos;&apos;\", \"-lsb-\", \"-rsb-\", \"-lcb-\", \"-rcb-\", \"-lrb-\", \"-rrb-\",\n",
    "           \"O&apos;MALLEY\", \"--\"]\n",
    "\n",
    "stop_chars = ['<', '>']\n",
    "\n",
    "# get all lemmas between a <story>-</story>-pair:\n",
    "stories = []\n",
    "lemma_stories = []\n",
    "with open('s_test.txt') as infile:\n",
    "    for line in infile:\n",
    "        l = line.rstrip()\n",
    "        if l == \"<story>\":\n",
    "            story = []\n",
    "        elif l == \"</story>\":\n",
    "            stories.append(story)\n",
    "        elif not any(stop_char in l for stop_char in stop_chars):\n",
    "                story.append(l)\n",
    "\n",
    "\n",
    "with open('lemma_test.txt') as infile:\n",
    "    for line in infile:\n",
    "        l = line.rstrip()\n",
    "        if l == \"<story>\":\n",
    "            story = []\n",
    "        elif l == \"</story>\":\n",
    "            lemma_stories.append(story)\n",
    "        elif not any(stop_char in l for stop_char in stop_chars):\n",
    "            if l not in en_stop:\n",
    "                story.append(l)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = stories\n",
    "y = lemma_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3045\n",
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# create dictionary and wordcounts corpus:\n",
    "dictionary = corpora.Dictionary(lemma_stories)\n",
    "#print(dictionary.token2id)\n",
    "dictionary.save(\"wordcounts.dict\")\n",
    "\n",
    "print(len(dictionary))\n",
    "\n",
    "\n",
    "# Bag-of-words representation of the stories.\n",
    "corpus = [dictionary.doc2bow(story) for story in stories]\n",
    "#print(corpus)\n",
    "#corpora.MmCorpus.serialize(\"corpus.mm\", corpus)\n",
    "print(len(corpus))\n",
    "print(len(stories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.interfaces.TransformedCorpus object at 0x10c20cf98>\n",
      "None\n",
      "\n",
      "Topics by Latent Dirichlet Allocation model\n",
      "Topic #1 (41, '0.026*\"wish\" + 0.020*\"together\" + 0.019*\"2016\" + 0.015*\"think\" + 0.015*\"time\" + 0.015*\"like\" + 0.015*\"year\" + 0.014*\"start\" + 0.014*\"also\" + 0.014*\"see\"')\n",
      "wish together 2016 think time like year start also see\n",
      "Topic #2 (11, '0.014*\"back\" + 0.012*\"new\" + 0.011*\"one\" + 0.010*\"car\" + 0.010*\"can\" + 0.009*\"also\" + 0.009*\"wife\" + 0.009*\"year\" + 0.009*\"good\" + 0.009*\"time\"')\n",
      "back new one car can also wife year good time\n",
      "Topic #3 (22, '0.027*\"year\" + 0.027*\"weird\" + 0.027*\"lot\" + 0.013*\"people\" + 0.013*\"think\" + 0.013*\"can\" + 0.013*\"horrifying\" + 0.013*\"believe\" + 0.013*\"wrong\" + 0.013*\"already\"')\n",
      "year weird lot people think can horrifying believe wrong already\n",
      "Topic #4 (5, '0.020*\"Trump\" + 0.016*\"also\" + 0.014*\"country\" + 0.013*\"campaign\" + 0.011*\"face\" + 0.011*\"Jeb\" + 0.011*\"Republicans\" + 0.011*\"Clinton\" + 0.011*\"trump\" + 0.010*\"Hillary\"')\n",
      "Trump also country campaign face Jeb Republicans Clinton trump Hillary\n",
      "Topic #5 (31, '0.000*\"year\" + 0.000*\"like\" + 0.000*\"know\" + 0.000*\"thing\" + 0.000*\"back\" + 0.000*\"one\" + 0.000*\"new\" + 0.000*\"best\" + 0.000*\"now\" + 0.000*\"God\"')\n",
      "year like know thing back one new best now God\n"
     ]
    }
   ],
   "source": [
    "# create tf.idf model:\n",
    "tfidf_model = models.TfidfModel(corpus)\n",
    "#tfidf_model.save(\"tfidf_model\")\n",
    "tfidf_corpus = tfidf_model[corpus]\n",
    "print(tfidf_corpus)\n",
    "print(tfidf_corpus.chunksize)\n",
    "# corpora.MmCorpus.serialize(\"tfidf_corpus.mm\", tfidf_corpus)\n",
    "#\n",
    "# # create topic models:\n",
    "# LDA\n",
    "num_topics = 50\n",
    "\n",
    "lda_model = models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, update_every=0, chunksize=2000, passes=20)\n",
    "#lda_model.save(\"lda_model\")\n",
    "lda_corpus = lda_model[corpus]\n",
    "#corpora.MmCorpus.serialize(\"lda_corpus.mm\", lda_corpus)\n",
    "\n",
    "print(\"\\nTopics by Latent Dirichlet Allocation model\")\n",
    "topics_found_lda = lda_model.print_topics(num_topics=5, num_words=10)\n",
    "all_topics = lda_model.print_topics(num_topics=50, num_words=10)\n",
    "\n",
    "# print(topics_found_lda)\n",
    "\n",
    "import re\n",
    "\n",
    "counter = 1\n",
    "for t in topics_found_lda:\n",
    "    print(\"Topic #{} {}\".format(counter, t))\n",
    "    words = re.findall('\"([^\"]+)\"', t[1])\n",
    "    words = ' '.join(words)\n",
    "    print(words)\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = []\n",
    "for t in all_topics:\n",
    "    words = re.findall('\"([^\"]+)\"', t[1])\n",
    "    words = ' '.join(words)\n",
    "    topics.append(words)\n",
    "    \n",
    "topics[0] = \"Topics\"\n",
    "#print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9, 0.98911111111111283)]\n"
     ]
    }
   ],
   "source": [
    "lda_df = pd.DataFrame(columns=range(50))\n",
    "lda_df.loc[0] = topics\n",
    "for i in range(len(stories)):\n",
    "    doc = lda_corpus[i]\n",
    "    for top, prob in doc:\n",
    "        lda_df.set_value(i, top, prob)\n",
    "print(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_df[0] = stories\n",
    "lda_df.iloc[0] = topics\n",
    "lda_df\n",
    "# Rows are the stories where first column contains the actual words that were used in the stories\n",
    "# Columns are the topics found in lda(the words are lemmas) \n",
    "lda_df.to_csv('short_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(lda_df[29])\n",
    "# print(lda_df.iloc[0, 29])\n",
    "# print(lda_df.iloc[27, 0])\n",
    "\n",
    "lda_df.iloc[1,0].to_csv('test.txt', header=True, index=False, sep='\\t', mode='a')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #6 (23, '0.023*\"year\" + 0.018*\"like\" + 0.013*\"police\" + 0.011*\"one\" + 0.010*\"world\" + 0.010*\"pope\" + 0.010*\"problem\" + 0.010*\"worst\" + 0.009*\"now\" + 0.008*\"people\"')\n",
      "year like police one world pope problem worst now people\n",
      "Topic #7 (19, '0.021*\"wish\" + 0.014*\"year\" + 0.014*\"also\" + 0.014*\"time\" + 0.014*\"like\" + 0.014*\"think\" + 0.014*\"2016\" + 0.014*\"bit\" + 0.014*\"see\" + 0.014*\"start\"')\n",
      "wish year also time like think 2016 bit see start\n",
      "Topic #8 (27, '0.000*\"one\" + 0.000*\"year\" + 0.000*\"know\" + 0.000*\"really\" + 0.000*\"new\" + 0.000*\"think\" + 0.000*\"sports\" + 0.000*\"ever\" + 0.000*\"like\" + 0.000*\"just\"')\n",
      "one year know really new think sports ever like just\n",
      "Topic #9 (28, '0.000*\"now\" + 0.000*\"year\" + 0.000*\"one\" + 0.000*\"first\" + 0.000*\"look\" + 0.000*\"2015\" + 0.000*\"solar\" + 0.000*\"moon\" + 0.000*\"like\" + 0.000*\"board\"')\n",
      "now year one first look 2015 solar moon like board\n",
      "Topic #10 (22, '0.040*\"Victor\" + 0.033*\"want\" + 0.022*\"teacher\" + 0.018*\"Whitney\" + 0.017*\"another\" + 0.017*\"$\" + 0.017*\"good\" + 0.015*\"take\" + 0.015*\"tomorrow\" + 0.015*\"elementary\"')\n",
      "Victor want teacher Whitney another $ good take tomorrow elementary\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
